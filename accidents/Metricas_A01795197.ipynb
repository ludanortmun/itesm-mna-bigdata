{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Actividad 4 | Métricas de calidad de resultados",
   "id": "36d0619c56400d92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:15.835493Z",
     "start_time": "2025-06-08T20:58:14.926202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MultilabelClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, StandardScaler, VectorAssembler\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col, hour, date_format, count, round, concat_ws, rand\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, percentile_approx\n",
    "import findspark\n"
   ],
   "id": "f6e6e2c4fed5b10c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\env_pyspark\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Construcción de la muestra M",
   "id": "aac9bd24bcb37b0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Primero descargaremos el dataset de forma local y creamos la sesión de PySpark.",
   "id": "c5b24782f1b8b2cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:16.482740Z",
     "start_time": "2025-06-08T20:58:15.851054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the latest version\n",
    "path = kagglehub.dataset_download(\"sobhanmoosavi/us-accidents\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "dataset_path = path + \"/US_Accidents_March23.csv\""
   ],
   "id": "c8aac55c4e7bd32b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\danie\\.cache\\kagglehub\\datasets\\sobhanmoosavi\\us-accidents\\versions\\13\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:28.237037Z",
     "start_time": "2025-06-08T20:58:17.026184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a Spark session\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "spark"
   ],
   "id": "f4c982c0e1eb9594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26d78769bb0>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DIU142O:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora podemos cargar nuestro dataset como un dataframe de PySpark.",
   "id": "6343e645d92e75e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:40.651897Z",
     "start_time": "2025-06-08T20:58:28.271605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.read.csv(dataset_path, header=True, inferSchema=True)\n",
    "\n",
    "df.show(5)"
   ],
   "id": "8f106b8ed9e74294",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "| ID| Source|Severity|         Start_Time|           End_Time|        Start_Lat|         Start_Lng|End_Lat|End_Lng|Distance(mi)|         Description|              Street|        City|    County|State|   Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "|A-1|Source2|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        39.865147|        -84.058723|   NULL|   NULL|        0.01|Right lane blocke...|              I-70 E|      Dayton|Montgomery|   OH|     45424|     US|US/Eastern|        KFFO|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|             0.02|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                Night|\n",
      "|A-2|Source2|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|39.92805900000001|        -82.831184|   NULL|   NULL|        0.01|Accident on Brice...|            Brice Rd|Reynoldsburg|  Franklin|   OH|43068-3402|     US|US/Eastern|        KCMH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|              0.0|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                  Day|\n",
      "|A-3|Source2|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        39.063148|        -84.032608|   NULL|   NULL|        0.01|Accident on OH-32...|      State Route 32|Williamsburg|  Clermont|   OH|     45176|     US|US/Eastern|        KI69|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|             NULL|         Overcast|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|         Night|         Night|              Day|                  Day|\n",
      "|A-4|Source2|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        39.747753|-84.20558199999998|   NULL|   NULL|        0.01|Accident on I-75 ...|              I-75 S|      Dayton|Montgomery|   OH|     45417|     US|US/Eastern|        KDAY|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|           Day|              Day|                  Day|\n",
      "|A-5|Source2|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        39.627781|        -84.188354|   NULL|   NULL|        0.01|Accident on McEwe...|Miamisburg Center...|      Dayton|Montgomery|   OH|     45459|     US|US/Eastern|        KMGY|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|           Day|           Day|              Day|                  Day|\n",
      "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A continuación aplicamos nuestro muestreo del conjunto de datos, tal como se describió en la actividad anterior.\n",
    "\n",
    "El primer paso consiste en crear las columnas Weather_Condition, Hora_Periodo y Tipo_Día."
   ],
   "id": "b8e54f81d0ebcb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:40.977848Z",
     "start_time": "2025-06-08T20:58:40.872674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.withColumn(\"Weather_Type\",\n",
    "    when(col(\"Weather_Condition\").isNull(), \"Desconocido\")\n",
    "    .when(col(\"Weather_Condition\").rlike(\"(?i)null|N/A\"), \"Desconocido\")\n",
    "    .when(col(\"Weather_Condition\").rlike(\"(?i)Rain|Drizzle|Thunder|Storm|Snow|Sleet|Hail|Ice|Fog|Haze|Mist|Dust|Sand|Smoke|Wintry|Squall|Tornado|Ash|Funnel\"), \"Adverso\")\n",
    "    .otherwise(\"Favorable\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"Hora_Periodo\",\n",
    "    when(hour(\"Start_Time\") < 6, \"Madrugada\")\n",
    "    .when(hour(\"Start_Time\") < 18, \"Alta actividad\")\n",
    "    .otherwise(\"Tarde-Noche\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"Dia_Semana\", date_format(\"Start_Time\", \"E\"))\n",
    "df = df.withColumn(\n",
    "    \"Tipo_Día\",\n",
    "    when(col(\"Dia_Semana\").isin(\"Sat\", \"Sun\"), \"Fin de semana\").otherwise(\"Laboral\")\n",
    ")"
   ],
   "id": "657291697acc8107",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Posteriormente, filtramos cualquier registro en el cual las columnas clave (Severity, Hora_Periodo, Tipo_Día y Weather_Type) son nulas.",
   "id": "35554b5d0327426e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:42.391878Z",
     "start_time": "2025-06-08T20:58:42.373642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_filtrado = df.filter(\n",
    "    (col(\"Severity\").isNotNull()) &\n",
    "    (col(\"Hora_Periodo\").isNotNull()) &\n",
    "    (col(\"Tipo_Día\").isNotNull()) &\n",
    "    (col(\"Weather_Type\").isNotNull())\n",
    ")"
   ],
   "id": "475928c6c383233f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora obtenemos los estratos a partir de las diferentes combinaciones de estas variables, al igual que la probabilidad para cada estrato.",
   "id": "a568fa9483d42fc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:46.902270Z",
     "start_time": "2025-06-08T20:58:42.827091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_registros = df_filtrado.count()\n",
    "\n",
    "estratos = df_filtrado.groupBy(\"Severity\", \"Hora_Periodo\", \"Tipo_Día\", \"Weather_Type\") \\\n",
    "    .agg(count(\"*\").alias(\"frecuencia\")) \\\n",
    "    .withColumn(\"probabilidad\", round(col(\"frecuencia\") / total_registros, 6)) \\\n",
    "    .orderBy(col(\"probabilidad\").desc())"
   ],
   "id": "7c12029359a779cd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para cada estrato, calculamos el número de elementos a incluir a partir del tamaño de la muestra deseado y la probabilidad para cada estrato. En este caso, buscamos una sub-muestra de 10,000 elementos.",
   "id": "5e545efffa9ea52c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:58:54.323392Z",
     "start_time": "2025-06-08T20:58:54.296991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tamaño total de muestra deseado\n",
    "n_muestra = 10000\n",
    "\n",
    "estratos = estratos.withColumn(\n",
    "    \"n_estrato\",\n",
    "    round(col(\"probabilidad\") * n_muestra).cast(\"integer\")\n",
    ")"
   ],
   "id": "b24cc9efd416e50a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Unimos los dataframes con la información de los estratos con nuestro dataset.",
   "id": "1e1b64b9ab3f39d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:59:02.050260Z",
     "start_time": "2025-06-08T20:59:01.968213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# En df_filtrado (base depurada sin nulos en variables clave)\n",
    "df_filtrado = df_filtrado.withColumn(\n",
    "    \"estrato_id\",\n",
    "    concat_ws(\"_\", \"Severity\", \"Hora_Periodo\", \"Tipo_Día\", \"Weather_Type\")\n",
    ")\n",
    "\n",
    "# Igual en la tabla de estratos con probabilidades y n_estrato\n",
    "estratos = estratos.withColumn(\n",
    "    \"estrato_id\",\n",
    "    concat_ws(\"_\", \"Severity\", \"Hora_Periodo\", \"Tipo_Día\", \"Weather_Type\")\n",
    ")\n",
    "\n",
    "df_muestreo = df_filtrado.join(\n",
    "    estratos.select(\"estrato_id\", \"n_estrato\"),\n",
    "    on=\"estrato_id\",\n",
    "    how=\"inner\"\n",
    ")"
   ],
   "id": "aa58838f80c51a3e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ordenamos de forma aleatoria los elementos dentro de cada estrato.",
   "id": "6d4231122e864a3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T20:59:36.401950Z",
     "start_time": "2025-06-08T20:59:36.329642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Asignar un número aleatorio y calcular el orden por estrato\n",
    "df_muestreo = df_muestreo.withColumn(\"rand\", rand(seed=42))\n",
    "\n",
    "window = Window.partitionBy(\"estrato_id\").orderBy(\"rand\")\n",
    "\n",
    "df_muestreo = df_muestreo.withColumn(\"row_num\", row_number().over(window))"
   ],
   "id": "7ad42b534dd1578f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finalmente, creamos nuestro data frame con la muestra a utilizar, incluyendo sólamente el número de elementos correspondiente a cada estrato.",
   "id": "855c79fda378ce16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:00:09.187492Z",
     "start_time": "2025-06-08T21:00:09.175226Z"
    }
   },
   "cell_type": "code",
   "source": "df_muestra_final = df_muestreo.filter(col(\"row_num\") <= col(\"n_estrato\"))",
   "id": "17fc812df608fde7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Una vez construida la muestra, podemos persistir el dataframe para que PySpark optimice las transformaciones posteriores. Al persistir el DataFrame, nos aseguramos de \"congelar\" su estado actual, de modo que cualquier operación posterior tenga un punto de partida definido.",
   "id": "37faf71b4249ef5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:01:16.192684Z",
     "start_time": "2025-06-08T21:01:16.110160Z"
    }
   },
   "cell_type": "code",
   "source": "df_muestra_final = df_muestra_final.persist()",
   "id": "8d2c3fe3d1597e49",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:03:21.127187Z",
     "start_time": "2025-06-08T21:03:05.823603Z"
    }
   },
   "cell_type": "code",
   "source": "df_muestra_final.summary()",
   "id": "85e7ddfb3e995258",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-------+--------------------+---------+-------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------+--------+---------+-----+------------------+-------+----------+------------+------------------+------------------+------------------+------------------+------------------+--------------+-----------------+--------------------+--------------------+--------------+--------------+-----------------+---------------------+------------+--------------+----------+-------------+------------------+--------------------+------------------+\n",
       "|summary|          estrato_id|       ID| Source|          Severity|         Start_Lat|         Start_Lng|          End_Lat|           End_Lng|      Distance(mi)|         Description|       Street|    City|   County|State|           Zipcode|Country|  Timezone|Airport_Code|    Temperature(F)|     Wind_Chill(F)|       Humidity(%)|      Pressure(in)|    Visibility(mi)|Wind_Direction|  Wind_Speed(mph)|   Precipitation(in)|   Weather_Condition|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|Weather_Type|  Hora_Periodo|Dia_Semana|     Tipo_Día|         n_estrato|                rand|           row_num|\n",
       "+-------+--------------------+---------+-------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------+--------+---------+-----+------------------+-------+----------+------------+------------------+------------------+------------------+------------------+------------------+--------------+-----------------+--------------------+--------------------+--------------+--------------+-----------------+---------------------+------------+--------------+----------+-------------+------------------+--------------------+------------------+\n",
       "|  count|               10003|    10003|  10003|             10003|             10003|             10003|             5552|              5552|             10003|               10003|         9996|   10002|    10003|10003|             10000|  10003|      9992|        9971|              9793|              7379|              9773|              9820|              9774|          9779|             9274|                7090|                9775|          9966|          9966|             9966|                 9966|       10003|         10003|     10003|        10003|             10003|               10003|             10003|\n",
       "|   mean|                NULL|     NULL|   NULL| 2.212636209137259| 36.21916174689025|-94.92490494333438|36.37626733720156|-96.25287156289144|0.5453729877488411|                NULL|         NULL|    NULL|     NULL| NULL|57144.058607021514|   NULL|      NULL|        NULL| 61.70130705606045|58.204553462528786| 65.03591527678297| 29.54638391038699| 9.095945365254758|          NULL|7.607321544101784|0.007464033850493648|                NULL|          NULL|          NULL|             NULL|                 NULL|        NULL|          NULL|      NULL|         NULL| 2107.662801159652|6.447993348574957E-4| 1054.331400579826|\n",
       "| stddev|                NULL|     NULL|   NULL|0.4878777238015975| 5.107221494122912|17.381733822325174|5.293945598709418|  18.1791928540894|1.5811612995445155|                NULL|         NULL|    NULL|     NULL| NULL|30800.081919386776|   NULL|      NULL|        NULL|18.914183626201737|22.315762210157292|22.727992539531076|0.9663792408880992|2.7315542242426742|          NULL|5.241953803631672| 0.04579050242853755|                NULL|          NULL|          NULL|             NULL|                 NULL|        NULL|          NULL|      NULL|         NULL|1861.2403085753288|3.846901241010442...|1234.8936379224372|\n",
       "|    min|1_Alta actividad_...|A-1000249|Source1|                 1|         24.651971|       -124.415166|        24.648098|       -124.415185|               0.0|#1 #2 #3 lane blo...| 100th Ave SE|Abingdon|Abbeville|   AL|        01007-9709|     US|US/Central|        K04W|             -15.0|             -35.0|               2.0|             20.02|               0.0|          CALM|              0.0|                 0.0|Blowing Dust / Windy|           Day|           Day|              Day|                  Day|     Adverso|Alta actividad|       Fri|Fin de semana|                 1|1.023707092429049...|                 1|\n",
       "|    25%|                NULL|     NULL|   NULL|                 2|33.408390000000004|       -117.268898|        33.546731|       -117.880255|               0.0|                NULL|         NULL|    NULL|     NULL| NULL|           30071.0|   NULL|      NULL|        NULL|              49.0|              42.0|              49.0|             29.36|              10.0|          NULL|              4.6|                 0.0|                NULL|          NULL|          NULL|             NULL|                 NULL|        NULL|          NULL|      NULL|         NULL|               501|3.219139866442733E-4|               119|\n",
       "|    50%|                NULL|     NULL|   NULL|                 2|         35.785198|-87.92536899999998|        36.179922|        -90.017958|             0.026|                NULL|         NULL|    NULL|     NULL| NULL|           55718.0|   NULL|      NULL|        NULL|              64.0|              62.0|              67.0|             29.86|              10.0|          NULL|              7.0|                 0.0|                NULL|          NULL|          NULL|             NULL|                 NULL|        NULL|          NULL|      NULL|         NULL|               995|6.337200378750962E-4|               473|\n",
       "|    75%|                NULL|     NULL|   NULL|                 2|         40.109268|        -80.434523|        40.329509|        -80.323107|             0.462|                NULL|         NULL|    NULL|     NULL| NULL|           90723.0|   NULL|      NULL|        NULL|              76.0|              75.0|              84.0|             30.03|              10.0|          NULL|             10.0|                 0.0|                NULL|          NULL|          NULL|             NULL|                 NULL|        NULL|          NULL|      NULL|         NULL|              4251|9.637690343168304E-4|              1751|\n",
       "|    max|4_Tarde-Noche_Lab...| A-998950|Source3|                 4|         48.904619|        -68.696929|        48.910452|        -68.688581|41.599998474121094|disabled vehicle ...|      Zion Rd|Zumbrota|     Yuba|   WY|             99224|     US|US/Pacific|        KZZV|             114.1|             114.0|             100.0|              31.0|              70.0|          West|             43.0|                1.53|          Wintry Mix|         Night|         Night|            Night|                Night|   Favorable|   Tarde-Noche|       Wed|      Laboral|              4251|0.006384820585985995|              4251|\n",
       "+-------+--------------------+---------+-------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------+--------+---------+-----+------------------+-------+----------+------------+------------------+------------------+------------------+------------------+------------------+--------------+-----------------+--------------------+--------------------+--------------+--------------+-----------------+---------------------+------------+--------------+----------+-------------+------------------+--------------------+------------------+"
      ],
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>estrato_id</th><th>ID</th><th>Source</th><th>Severity</th><th>Start_Lat</th><th>Start_Lng</th><th>End_Lat</th><th>End_Lng</th><th>Distance(mi)</th><th>Description</th><th>Street</th><th>City</th><th>County</th><th>State</th><th>Zipcode</th><th>Country</th><th>Timezone</th><th>Airport_Code</th><th>Temperature(F)</th><th>Wind_Chill(F)</th><th>Humidity(%)</th><th>Pressure(in)</th><th>Visibility(mi)</th><th>Wind_Direction</th><th>Wind_Speed(mph)</th><th>Precipitation(in)</th><th>Weather_Condition</th><th>Sunrise_Sunset</th><th>Civil_Twilight</th><th>Nautical_Twilight</th><th>Astronomical_Twilight</th><th>Weather_Type</th><th>Hora_Periodo</th><th>Dia_Semana</th><th>Tipo_D&iacute;a</th><th>n_estrato</th><th>rand</th><th>row_num</th></tr>\n",
       "<tr><td>count</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>5552</td><td>5552</td><td>10003</td><td>10003</td><td>9996</td><td>10002</td><td>10003</td><td>10003</td><td>10000</td><td>10003</td><td>9992</td><td>9971</td><td>9793</td><td>7379</td><td>9773</td><td>9820</td><td>9774</td><td>9779</td><td>9274</td><td>7090</td><td>9775</td><td>9966</td><td>9966</td><td>9966</td><td>9966</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td><td>10003</td></tr>\n",
       "<tr><td>mean</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2.212636209137259</td><td>36.21916174689025</td><td>-94.92490494333438</td><td>36.37626733720156</td><td>-96.25287156289144</td><td>0.5453729877488411</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>57144.058607021514</td><td>NULL</td><td>NULL</td><td>NULL</td><td>61.70130705606045</td><td>58.204553462528786</td><td>65.03591527678297</td><td>29.54638391038699</td><td>9.095945365254758</td><td>NULL</td><td>7.607321544101784</td><td>0.007464033850493648</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2107.662801159652</td><td>6.447993348574957E-4</td><td>1054.331400579826</td></tr>\n",
       "<tr><td>stddev</td><td>NULL</td><td>NULL</td><td>NULL</td><td>0.4878777238015975</td><td>5.107221494122912</td><td>17.381733822325174</td><td>5.293945598709418</td><td>18.1791928540894</td><td>1.5811612995445155</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>30800.081919386776</td><td>NULL</td><td>NULL</td><td>NULL</td><td>18.914183626201737</td><td>22.315762210157292</td><td>22.727992539531076</td><td>0.9663792408880992</td><td>2.7315542242426742</td><td>NULL</td><td>5.241953803631672</td><td>0.04579050242853755</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>1861.2403085753288</td><td>3.846901241010442...</td><td>1234.8936379224372</td></tr>\n",
       "<tr><td>min</td><td>1_Alta actividad_...</td><td>A-1000249</td><td>Source1</td><td>1</td><td>24.651971</td><td>-124.415166</td><td>24.648098</td><td>-124.415185</td><td>0.0</td><td>#1 #2 #3 lane blo...</td><td> 100th Ave SE</td><td>Abingdon</td><td>Abbeville</td><td>AL</td><td>01007-9709</td><td>US</td><td>US/Central</td><td>K04W</td><td>-15.0</td><td>-35.0</td><td>2.0</td><td>20.02</td><td>0.0</td><td>CALM</td><td>0.0</td><td>0.0</td><td>Blowing Dust / Windy</td><td>Day</td><td>Day</td><td>Day</td><td>Day</td><td>Adverso</td><td>Alta actividad</td><td>Fri</td><td>Fin de semana</td><td>1</td><td>1.023707092429049...</td><td>1</td></tr>\n",
       "<tr><td>25%</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2</td><td>33.408390000000004</td><td>-117.268898</td><td>33.546731</td><td>-117.880255</td><td>0.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>30071.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>49.0</td><td>42.0</td><td>49.0</td><td>29.36</td><td>10.0</td><td>NULL</td><td>4.6</td><td>0.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>501</td><td>3.219139866442733E-4</td><td>119</td></tr>\n",
       "<tr><td>50%</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2</td><td>35.785198</td><td>-87.92536899999998</td><td>36.179922</td><td>-90.017958</td><td>0.026</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>55718.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>64.0</td><td>62.0</td><td>67.0</td><td>29.86</td><td>10.0</td><td>NULL</td><td>7.0</td><td>0.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>995</td><td>6.337200378750962E-4</td><td>473</td></tr>\n",
       "<tr><td>75%</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2</td><td>40.109268</td><td>-80.434523</td><td>40.329509</td><td>-80.323107</td><td>0.462</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>90723.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>76.0</td><td>75.0</td><td>84.0</td><td>30.03</td><td>10.0</td><td>NULL</td><td>10.0</td><td>0.0</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>4251</td><td>9.637690343168304E-4</td><td>1751</td></tr>\n",
       "<tr><td>max</td><td>4_Tarde-Noche_Lab...</td><td>A-998950</td><td>Source3</td><td>4</td><td>48.904619</td><td>-68.696929</td><td>48.910452</td><td>-68.688581</td><td>41.599998474121094</td><td>disabled vehicle ...</td><td>Zion Rd</td><td>Zumbrota</td><td>Yuba</td><td>WY</td><td>99224</td><td>US</td><td>US/Pacific</td><td>KZZV</td><td>114.1</td><td>114.0</td><td>100.0</td><td>31.0</td><td>70.0</td><td>West</td><td>43.0</td><td>1.53</td><td>Wintry Mix</td><td>Night</td><td>Night</td><td>Night</td><td>Night</td><td>Favorable</td><td>Tarde-Noche</td><td>Wed</td><td>Laboral</td><td>4251</td><td>0.006384820585985995</td><td>4251</td></tr>\n",
       "</table>\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Construcción Train - Test",
   "id": "9ace85ec07ed7c76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Previo a la construcción de los conjuntos train y test, vamos a realizar una limpieza de datos.\n",
    "Esto consiste en:\n",
    "- Eliminar columnas con metadatos que no proporcionarán valor a ningún modelo\n",
    "- Eliminar columnas que son redundantes con otras columnas en el conjunto de datos\n",
    "- Eliminar columnas donde más del 5% de los registros son valores faltantes\n",
    "- De las columnas restantes, eliminar los registros donde existan valores faltantes"
   ],
   "id": "11d04e454f719fa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:03:57.059234Z",
     "start_time": "2025-06-08T21:03:57.054507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comenzamos con la limpieza de las columnas agregadas para el sub muestreo\n",
    "cols_to_drop = ['ID', 'estrato_id', 'n_estrato', 'rand', 'row_num', 'rand', 'Source']\n"
   ],
   "id": "ab68c559a24015f3",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:04:30.077083Z",
     "start_time": "2025-06-08T21:04:30.072971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ahora las columnas irrelevantes o redundantes.\n",
    "cols_to_drop += ['Start_Lng', 'End_Lng', 'Start_Lat', 'End_Lat', 'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'Wind_Chill(F)', 'Description', 'Wind_Direction', 'Sunrise_Sunset']\n"
   ],
   "id": "8fd48956e45998a9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:05:34.026482Z",
     "start_time": "2025-06-08T21:05:08.009770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ignoramos las columnas que ya identificamos como columnas a remover\n",
    "cols = [c for c in df_muestra_final.columns if c not in cols_to_drop]\n",
    "total = df_muestra_final.count()\n",
    "\n",
    "for c in cols:\n",
    "    n_missing = df_muestra_final.filter(col(c).isNull()).count()\n",
    "    if n_missing > (total*0.05):\n",
    "        print(f'Dropping column {c}')\n",
    "        cols_to_drop.append(c)\n"
   ],
   "id": "a74d47d15b89a9c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column Wind_Speed(mph)\n",
      "Dropping column Precipitation(in)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:06:07.991117Z",
     "start_time": "2025-06-08T21:06:07.968153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols = [c for c in df_muestra_final.columns if c not in cols_to_drop]\n",
    "df_muestra_final = df_muestra_final.dropna(subset=cols)"
   ],
   "id": "e8944d5086cafe2f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Una vez realizada la limpieza de datos, podemos proceder a crear nuestros conjuntos de train y test. Para este ejercicio, se utilizará una proporción de 80/20, la cual es comúnmnente utilizada en problemas de aprendizaje de máquina.",
   "id": "5cd169933d2af7de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:06:48.589701Z",
     "start_time": "2025-06-08T21:06:45.670782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data,test_data = df_muestra_final.randomSplit([0.8,0.2], seed = 42)\n",
    "print(f\"\"\"Existen {train_data.count()} instancias en el conjunto train, y {test_data.count()} en el conjunto test\"\"\")"
   ],
   "id": "49feea82b4341b9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existen 7799 instancias en el conjunto train, y 1898 en el conjunto test\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Selección de métricas para medir calidad de resultados",
   "id": "7daa542c847581cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "El modelo de aprendizaje automático a crear durante este ejercicio será un modelo de clasificación binaria. La intención de este modelo es predecir si un accidente será de baja o alta severidad, basado en las condiciones bajo las cuales sucedió.\n",
    "\n",
    "El caso de uso hipotético para este modelo es por parte de los equipos de respuesta a accidentes; la intención será que, una vez recibido un reporte de accidente, puedan utilizar este modelo para predecir su severidad y priorizar los recursos de respuesta de forma apropiada e informada.\n",
    "\n",
    "Debido a que se trata de un modelo de clasificación binaria, se utilizarán las siguientes métricas para evaluar la calidad del modelo:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "\n",
    "Además, considerando el contexto del problema, la métrica para la cual se busca optimizar será recall. Esto es debido a que se busca reducir la cantidad de falsos negativos; es decir, reducir la cantidad de accidentes de alta severidad que son catalogados como baja severidad. El razonamiento detrás de esta decisión es que el costo de un falso negativo (no atender inmediatamente un accidente grave) es mayor que el costo de un falso positivo (atender inmediatamente un accidente leve)."
   ],
   "id": "1c1a7ee295f612f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Entrenamiento de Modelos de Aprendizaje",
   "id": "6dd9b5bf6ad2b873"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Antes de comenzar a entrenar nuestro modelo, se realizará preprocesamiento básico del dataset con la finalidad de prepararlo para el entrenamiento.\n",
    "\n",
    "La primera transformación consiste en crear una columna \"Minutes\" calculada a partir del tiempo de inicio y final de los accidentes. En el caso de uso hipotético en el que los equipos de respuesta utilizarán este modelo, la columna se calculará a partir de la hora a la que se reportó el accidente y la hora actual."
   ],
   "id": "11d4c2c82857e107"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:07:27.918150Z",
     "start_time": "2025-06-08T21:07:27.876319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data.withColumn('Minutes', (col('End_Time').cast('long') - col('Start_Time').cast('long')) / 60)\n",
    "test_data = train_data.withColumn('Minutes', (col('End_Time').cast('long') - col('Start_Time').cast('long')) / 60)"
   ],
   "id": "5632afad29d89851",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora procedemos a eliminar outliers mediante la técnica IQR. Esto lo aplicaremos a las columnas Minutes y Distance.",
   "id": "154d6160f39daf0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:07:29.392966Z",
     "start_time": "2025-06-08T21:07:27.976010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Q1 and Q3\n",
    "quantiles = train_data.select(\n",
    "    percentile_approx('Minutes', [0.25, 0.75], 10000).alias('quantiles')\n",
    ").collect()[0]['quantiles']\n",
    "\n",
    "Q1 = quantiles[0]\n",
    "Q3 = quantiles[1]\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out outliers\n",
    "train_data = train_data.filter(\n",
    "    (col('Minutes') >= Q1 - 1.5 * IQR) &\n",
    "    (col('Minutes') <= Q3 + 1.5 * IQR)\n",
    ")\n",
    "test_data = test_data.filter(\n",
    "    (col('Minutes') >= Q1 - 1.5 * IQR) &\n",
    "    (col('Minutes') <= Q3 + 1.5 * IQR)\n",
    ")"
   ],
   "id": "82d143c5eaba7350",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:08:45.509115Z",
     "start_time": "2025-06-08T21:08:44.429124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Q1 and Q3\n",
    "quantiles = train_data.select(\n",
    "    percentile_approx('Distance(mi)', [0.25, 0.75], 10000).alias('quantiles')\n",
    ").collect()[0]['quantiles']\n",
    "\n",
    "Q1 = quantiles[0]\n",
    "Q3 = quantiles[1]\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out outliers\n",
    "train_data = train_data.filter(\n",
    "    (col('Distance(mi)') >= Q1 - 1.5 * IQR) &\n",
    "    (col('Distance(mi)') <= Q3 + 1.5 * IQR)\n",
    ")\n",
    "test_data = test_data.filter(\n",
    "    (col('Distance(mi)') >= Q1 - 1.5 * IQR) &\n",
    "    (col('Distance(mi)') <= Q3 + 1.5 * IQR)\n",
    ")"
   ],
   "id": "884e0b4bd86f7433",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora procedemos a crear nuestra columna objetivo a partir de la columna Severity. Para este ejercicio, severidades 1 y 2 se considerarán como accidentes leves, mientras que las severidades 3 y 4 se considerarán accidentes graves.",
   "id": "730a8728a4e2d60d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:09:20.347692Z",
     "start_time": "2025-06-08T21:09:20.320051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = train_data.withColumn('IsSevere', (col('Severity') > 2).cast(\"double\"))\n",
    "test_data = test_data.withColumn('IsSevere', (col('Severity') > 2).cast(\"double\"))"
   ],
   "id": "2ee563d6aeedf781",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora bien, procedemos a crear nuestro vector de características. Para este ejercicio, consideraremos las variables numéricas Distance, Visibility y Minutes; así como las variables categóricas Weather_Type, Hora_Periodo y Tipo_Día.",
   "id": "b4fe92c108c2cfc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para las variables numéricas, aplicamos escalamiento estándar.",
   "id": "162f97037b01a292"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:10:00.437419Z",
     "start_time": "2025-06-08T21:09:58.314787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_to_scale = ['Distance(mi)', 'Visibility(mi)', 'Minutes']\n",
    "\n",
    "vectorizer = VectorAssembler(inputCols=cols_to_scale, outputCol=\"numerical_features\")\n",
    "train_data = vectorizer.transform(train_data)\n",
    "test_data = vectorizer.transform(test_data)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"numerical_features\", outputCol=\"scaled_features\")\n",
    "fitted_scaler = scaler.fit(train_data)\n",
    "train_data = fitted_scaler.transform(train_data)\n",
    "test_data = fitted_scaler.transform(test_data)\n"
   ],
   "id": "bb7cbde2ae8785f3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Por su parte, las variables categóricas deben ser indexadas primero, para posteriormente codificar mediante One Hot encoding.",
   "id": "fe721abe4ce2ed3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:10:45.725880Z",
     "start_time": "2025-06-08T21:10:40.202026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_columns = ['Weather_Type', 'Dia_Semana', 'Tipo_Día', 'Hora_Periodo']\n",
    "\n",
    "# Primero convertimos todas las columnas a índices\n",
    "for c in categorical_columns:\n",
    "    indexer = StringIndexer(inputCol=c, outputCol=f\"{c}_index\", handleInvalid='keep')\n",
    "    fitted_indexer = indexer.fit(train_data)\n",
    "    train_data = fitted_indexer.transform(train_data)\n",
    "    test_data = fitted_indexer.transform(test_data)"
   ],
   "id": "e9db7eaf61ec30fd",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:11:22.175528Z",
     "start_time": "2025-06-08T21:11:22.069917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_index_cols = [f\"{c}_index\" for c in categorical_columns]\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=categorical_index_cols, outputCols=[f\"{c}_vector\" for c in categorical_columns], handleInvalid='keep')\n",
    "fitted_encoder = encoder.fit(train_data)\n",
    "train_data = fitted_encoder.transform(train_data)\n",
    "test_data = fitted_encoder.transform(test_data)"
   ],
   "id": "64210510ed5aa8e7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora creamos un solo vector que contenga las características para entrenar nuestro modelo.",
   "id": "3c0ddf708ca545d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:11:58.332135Z",
     "start_time": "2025-06-08T21:11:58.268359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_to_vectorize = ['Weather_Type_vector', 'Tipo_Día_vector', 'Hora_Periodo_vector', 'Severity', 'scaled_features']\n",
    "vectorizer = VectorAssembler(inputCols=cols_to_vectorize, outputCol=\"input_features\")\n",
    "train_data = vectorizer.transform(train_data)\n",
    "test_data = vectorizer.transform(test_data)"
   ],
   "id": "a847686e4f5167bf",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Debido a que se trata de un problema no balanceado, podemos agregar peso a nuestras clases. Esto evitará sesgos a favor de la clase mayoritaria.",
   "id": "c796842a3db30919"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:48:42.251262Z",
     "start_time": "2025-06-08T21:48:40.044535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "severe_percentage = test_data.where(col('IsSevere') == 1).count() / test_data.count()\n",
    "severe_weight = 1 - severe_percentage\n",
    "print(\"Weights:\")\n",
    "print(f\"Severe: {severe_weight}\")\n",
    "print(f\"Not severe: {1 - severe_weight}\")\n",
    "\n",
    "train_data = train_data.withColumn('weight', when(col('IsSevere') == 1, severe_weight).otherwise((1-severe_weight)))\n",
    "test_data = test_data.withColumn('weight', when(col('IsSevere') == 1, severe_weight).otherwise((1-severe_weight)))"
   ],
   "id": "8e0c1140b1bd08e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "Severe: 0.7995341873232407\n",
      "Not severe: 0.20046581267675934\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finalmente, podemos crear un modelo de clasificación. Primero entrenamos con nuestro conjunto de train.",
   "id": "bd5cfb3377184bd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:52:05.613011Z",
     "start_time": "2025-06-08T21:51:43.650171Z"
    }
   },
   "cell_type": "code",
   "source": "log_regression = LogisticRegression(featuresCol='input_features', labelCol='IsSevere', weightCol='weight').fit(train_data)",
   "id": "5d4acd1aaab04419",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Posteriormente, obtenemos las predicciones correspondientes al conjunto de test.",
   "id": "e10f97e42f7cbcda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:52:39.644475Z",
     "start_time": "2025-06-08T21:52:39.567758Z"
    }
   },
   "cell_type": "code",
   "source": "test_predictions = log_regression.transform(test_data)",
   "id": "d32b884e7007922d",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A partir de estas predicciones, podemos obtener las métricas de desempeño. En este caso, utilizaremos el `MultilabelClassificationEvaluator` de PySpark para evaluar nuestras métricas. Este objeto requiere un dataframe con dos columnas en forma de arreglo, una con la predicción y otra con la etiqueta real. Preparamos nuestro dataframe en este formato.",
   "id": "130038790ec27a29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:53:14.824911Z",
     "start_time": "2025-06-08T21:53:14.752743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_assembler = VectorAssembler(inputCols=['IsSevere'], outputCol='label')\n",
    "pred_assembler = VectorAssembler(inputCols=['prediction'], outputCol='pred')\n",
    "\n",
    "test_predictions = (pred_assembler.transform(label_assembler.transform(test_predictions))\n",
    "         .select(vector_to_array(col('pred')).alias('pred'), vector_to_array(col('label')).alias('label')))"
   ],
   "id": "79f55c121ef4193e",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:54:07.175420Z",
     "start_time": "2025-06-08T21:54:03.132383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_accuracy = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='accuracy').evaluate(test_predictions)\n",
    "test_recall = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='recall').evaluate(test_predictions)\n",
    "test_precision = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='precision').evaluate(test_predictions)\n",
    "test_f1 = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='f1Measure').evaluate(test_predictions)"
   ],
   "id": "1b661faf540dd6db",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:54:38.913995Z",
     "start_time": "2025-06-08T21:54:38.909903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Accuracy: {test_accuracy:.3f}')\n",
    "print(f'Recall: {test_recall:.3f}')\n",
    "print(f'Precision: {test_precision:.3f}')\n",
    "print(f'F1: {test_f1:.3f}')"
   ],
   "id": "887b99447c835a98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "Recall: 1.000\n",
      "Precision: 1.000\n",
      "F1: 1.000\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Repetimos el proceso de evaluación para el conjunto de entrenamiento, con la intención de determinar si nuestro modelo está sobre-ajustado o no. Un modelo sobre-ajustado tendrá un rendimiento significativamente superior con el conjunto de entrenamiento.",
   "id": "3351db107ca17d99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T21:55:14.538585Z",
     "start_time": "2025-06-08T21:55:10.891527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_predictions = log_regression.transform(train_data)\n",
    "train_predictions = (pred_assembler.transform(label_assembler.transform(train_predictions))\n",
    "         .select(vector_to_array(col('pred')).alias('pred'), vector_to_array(col('label')).alias('label')))\n",
    "\n",
    "train_accuracy = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='accuracy').evaluate(train_predictions)\n",
    "train_recall = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='recall').evaluate(train_predictions)\n",
    "train_precision = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='precision').evaluate(train_predictions)\n",
    "train_f1 = MultilabelClassificationEvaluator(predictionCol='pred', labelCol='label', metricName='f1Measure').evaluate(train_predictions)\n",
    "\n",
    "print(f'Accuracy: {train_accuracy:.3f}')\n",
    "print(f'Recall: {train_recall:.3f}')\n",
    "print(f'Precision: {train_precision:.3f}')\n",
    "print(f'F1: {train_f1:.3f}')"
   ],
   "id": "5dd9b5f828ec5124",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n",
      "Recall: 1.000\n",
      "Precision: 1.000\n",
      "F1: 1.000\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Análisis de resultados",
   "id": "16ef2c1633dae5c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como podemos observar, el modelo de regresión logística obtenido a partir de este entrenamiento presenta un rendimiento perfecto, tanto en el conjunto de pruebas como en el conjunto de entrenamiento. Debido a que ambos conjuntos presentan el mismo rendimiento, no se sospecha de sobre-ajuste.\n",
    "\n",
    "Si bien no es común obtener modelos con rendimiento perfecto, existen posibles causas para esto:\n",
    "- La calidad de la información en el conjunto de datos original permite el entrenamiento de un modelo de clasificación perfecto\n",
    "- El preprocesamiento aplicado durante este ejercicio elimina la posibilidad de \"ruido\" que afectaría el rendimiento del modelo\n",
    "\n",
    "Cabe destacar que en este ejercicio se utilizó una muestra de 10,000 elementos (de un total de 7.7 millones), por lo que es probable que en caso de incrementar el tamaño de la muestra, el rendimiento del modelo disminuya."
   ],
   "id": "d7abb2a6086b01a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
